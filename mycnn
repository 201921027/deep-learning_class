import torch
import torch.nn as nn
import torchvision.datasets as dset
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable
import matplotlib.pyplot as plt
%matplotlib inline

mnist_train= dset.MNIST("", train= True, transform= transforms.ToTensor(),
                       target_transform= None, download= True)
mnist_test= dset.MNIST("", train= False, transform= transforms.ToTensor(),
                       target_transform= None, download= True)
                       
print "mnist_train 길이: ", len(mnist_train)
print "mnist_test 길이: ", len(mnist_test)

#데이터 하나 형태
image, label= mnist_train.__getitem__(0) #0th data
print "image data 형태: ", image.size()
print "label: ", label

#그리기
img= image.numpy() #image type -> numpy type(1, 28, 28)
plt.title("label: %d"%label)
plt.imshow(img[0], cmap= 'gray')
plt.show()

print(mnist_train[0][1]) #0th data' label
print(mnist_train[0][0].size()) #0th data' image size

for i in range(3):
    img= mnist_train[i][0].numpy() # i번째 data' image를 numpy 형태로
    print(mnist_train[i][1]) #i번째 data' label 출력
    plt.imshow(img[0], cmap= 'gray') #i번째 data' image
    plt.show()
    
#mnist의 첫 번째 이미지, 라벨 가져오기
image, label= mnist_train[0]

#[1, 28, 28]-> [1, 1, 28, 28] : 
#추가된 1: batch_size(이번엔 데이터 1개만 넣어볼 거라 batch_size=1)
image= image.view(-1, image.size()[0], image.size()[1], image.size()[2])
print(image.size())

print label

#convolutional filter 정의
conv_layer= nn.Conv2d(in_channels=1, out_channels=3, kernel_size= 3, padding=1)
#image에 filter 적용(아무것도 지정 안 했으므로 default filter 적용됨)
output= conv_layer(Variable(image))
print(output.size())

for i in range(3): #channel에 따라 그리겠다
    # 해당 channel에 속하는 모든 원소(h, w)를 그리겠다
    plt.imshow(output[0, i, :, :].data.numpy(), cmap= 'gray')
    plt.show()
    
    
import numpy as np
import torch.optim as optim

batch_size= 16
learning_rate= 0.0002
num_epoch= 10

train_loader= torch.utils.data.DataLoader(list(mnist_train)[:batch_size*100], 
                                         batch_size=batch_size, shuffle=True,
                                         num_workers=2, drop_last=True)
test_loader= torch.utils.data.DataLoader(mnist_test, 
                                         batch_size=batch_size, shuffle=False,
                                         num_workers=2, drop_last=True)
                                         
                                         
# cnn class 만들기(모델 만들기)
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.layer= nn.Sequential(
            
            # (I - F + 2P)/S +1 -> (28- 5 + 2*2)/1 +1 = 28(next layer' img size)
            #input # of channel =1, # of feature map(: # of channel)= 16, 
            #kernel size= 5
            #학습시켜야할 # of parameter: (5*5*1)*16 +16(bias)
            nn.Conv2d(1, 16, 5, padding= 2),
            nn.ReLU(),
            
            # (I - F + 2P)/S +1 -> (28- 5 + 2*2)/1 +1 = 28(next layer' img size)
            #input # of channel =16, feature map size(: # of channel)= 32
            #학습시켜야할 # of parameter: (5*5*16)*32 +32(bias)
            nn.Conv2d(16, 32, 5, padding= 2),
            nn.ReLU(),
            nn.MaxPool2d(2,2), # 28*28 -> 14*14(h*w) (-> channel 수는 그대로)
            
            # (I - F + 2P)/S +1 -> (14- 5 + 2*2)/1 +1 = 14(next layer' img size)
            #input # of channel =32, feature map size(: # of channel)= 64
            #학습시켜야할 # of parameter: (5*5*32)*64 +64(bias)
            nn.Conv2d(32, 64, 5, padding= 2),
            nn.ReLU(),
            nn.MaxPool2d(2,2) #14*14 -> 7*7(h*w) (-> channel 수는 그대로)
            )
        
        self.fc_layer= nn.Sequential( #fully-connected-layer
            nn.Linear(64*7*7, 100),
            nn.ReLU(),
            nn.Linear(100, 10)
        )
        
    def forward(self, x):
        out= self.layer(x)
        out= out.view(batch_size, -1)
        out= self.fc_layer(out)
        return out
        

model= CNN()        


#파라미터 체크하기
for parameter in model.parameters():
    #print(parameter) -> kernel의 실제 원소값이 출력됨
    print(parameter.shape)
    
    
#loss function, optimizer 선언
loss_func= nn.CrossEntropyLoss()
optimizer= torch.optim.Adam(model.parameters(), lr= learning_rate)


#optimization

for i in range(num_epoch):
    for j, [image, label] in enumerate(train_loader): #batch_size만큼
        x= Variable(image)
        y_= Variable(label)
        
        optimizer.zero_grad() #optimizer 안에서 이전 gradient들을 초기화
        output= model.forward(x)
        loss= loss_func(output, y_)
        loss.backward() #gradient 계산
        optimizer.step #parameter update
        
        if j%50==0:
            print(loss, j, i)
            
            
#모델 저장시키기
torch.save(model, 'nets/mycnn_model_%d.pkl'%(num_epoch))

try:
    #미리 학습시킨 네트워크의 파라미터 집합
    model= torch.load('nets/mycnn_model_10.pkl')
    print("model restored")
except:
    print("model not resotred")
    
    
def ComputeAccr(dloader, imodel):
    correct= 0
    total= 0
    
    for j, [imgs, labels] in enumerate(dloader): #batch_size 만큼
        img= Variable(imgs) #x
        label= Variable(labels) #y
        
        output= imodel.forward(img)
        _, output_index= torch.max(output, 1)
        
        total += label.size(0)
        correct += (output_index == label).sum().float()
    print("Accuracy of Test Data: {}".format(100*correct/total))


ComputeAccr(test_loader, model)
